{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, mean_squared_error\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r wp4\n",
    "wp4 = wp4\n",
    " \n",
    "%store -r wp8\n",
    "wp8 = wp8\n",
    "\n",
    "%store -r dwt4\n",
    "dwt4 = dwt4\n",
    "\n",
    "%store -r dwt8\n",
    "dwt8 = dwt8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Repeated Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_rep_samples(df, n_iter = 1000): #default 1k iterations\n",
    "    df = df\n",
    "    x = df.loc[:, df.columns != 'state'] #features\n",
    "    y = df.loc[:, df.columns == 'state'] #supervisor\n",
    "\n",
    "    eval_metrics = {} #empty dictionary to store metrics\n",
    "\n",
    "    for i in range(n_iter): \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.67)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        log_model = LogisticRegression(class_weight='balanced')\n",
    "        log_model.fit(x_train, y_train.values.ravel())\n",
    "        y_pred = log_model.predict(x_test)\n",
    "\n",
    "        accuracy = classification_report(y_test, y_pred, output_dict=True)['accuracy']\n",
    "        specificity = classification_report(y_test, y_pred, output_dict=True)['0']['recall'] #recall of the negative class = specificity\n",
    "        sensitivity = classification_report(y_test, y_pred, output_dict=True)['1']['recall'] #recall of the positive class = sensitivity\n",
    "\n",
    "        metrics = [accuracy, specificity, sensitivity] #store values in list\n",
    "        eval_metrics[i]=list(metrics) #store list in dictionary\n",
    "\n",
    "    eval_metrics = pd.DataFrame.from_dict(eval_metrics).T \n",
    "    eval_metrics.columns = ['accuracy', 'specificity', 'sensitivity']\n",
    "    eval_metrics.head()\n",
    "\n",
    "    means = eval_metrics.mean(axis=0) #mean of each column\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Wavelet Packet / Wang, 4-3-02 data (wp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy       0.860645\n",
       "specificity    0.849033\n",
       "sensitivity    0.873112\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_rep_samples(df = wp4, n_iter = 10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Wavelet Packet / Wang, 8-7-02 data (wp8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy       0.960526\n",
       "specificity    0.956043\n",
       "sensitivity    0.963150\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_rep_samples(df = wp8, n_iter = 10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Discrete Wavelet Transform, 4-3-02 data (dwt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy       0.879708\n",
       "specificity    0.874583\n",
       "sensitivity    0.885560\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_rep_samples(df = dwt4, n_iter = 10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Discrete Wavelet Transform, 8-7-02 data (dwt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy       0.954730\n",
       "specificity    0.953027\n",
       "sensitivity    0.955852\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_rep_samples(df = dwt8, n_iter = 10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Grid Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Significant accuracy discrepancy between random state = 0 and random state = 1 between two grid search functions:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### random_state = 0, with accuracy = 0.952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9523809523809523\n",
      "Specificity:  0.9666666666666667\n",
      "Sensitivity:  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "x = dwt8.loc[:, dwt8.columns != 'state'] #features\n",
    "y = dwt8.loc[:, dwt8.columns == 'state'] #supervisor\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.67, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "log_reg_model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"scaler\", scaler), (\"log_reg\", log_reg_model)])\n",
    "\n",
    "param_grid = {\n",
    "    #'log_reg__penalty': ['none', 'l2'],\n",
    "    'log_reg__C':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_model = GridSearchCV(pipeline, param_grid, n_jobs=1)\n",
    "grid_model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % grid_model.best_score_)\n",
    "#print(grid_model.best_params_)\n",
    "\n",
    "y_pred = grid_model.predict(x_test)\n",
    "\n",
    "accuracy = classification_report(y_test, y_pred, output_dict=True)['accuracy']\n",
    "specificity = classification_report(y_test, y_pred, output_dict=True)['0']['recall'] #recall of the negative class = specificity\n",
    "sensitivity = classification_report(y_test, y_pred, output_dict=True)['1']['recall'] #recall of the positive class = sensitivity\n",
    "\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Specificity: ', specificity)\n",
    "print('Sensitivity: ', sensitivity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### random_state = 1, with accuracy = 0.929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9285714285714286\n",
      "Specificity:  0.8823529411764706\n",
      "Sensitivity:  0.96\n"
     ]
    }
   ],
   "source": [
    "x = dwt8.loc[:, dwt8.columns != 'state'] #features\n",
    "y = dwt8.loc[:, dwt8.columns == 'state'] #supervisor\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.67, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "log_reg_model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"scaler\", scaler), (\"log_reg\", log_reg_model)])\n",
    "\n",
    "param_grid = {\n",
    "    #'log_reg__penalty': ['none', 'l2'],\n",
    "    'log_reg__C':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_model = GridSearchCV(pipeline, param_grid, n_jobs=1)\n",
    "grid_model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % grid_model.best_score_)\n",
    "#print(grid_model.best_params_)\n",
    "\n",
    "y_pred = grid_model.predict(x_test)\n",
    "\n",
    "accuracy = classification_report(y_test, y_pred, output_dict=True)['accuracy']\n",
    "specificity = classification_report(y_test, y_pred, output_dict=True)['0']['recall'] #recall of the negative class = specificity\n",
    "sensitivity = classification_report(y_test, y_pred, output_dict=True)['1']['recall'] #recall of the positive class = sensitivity\n",
    "\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Specificity: ', specificity)\n",
    "print('Sensitivity: ', sensitivity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Repeated Sampling with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_grid_reps(df, n_iter = 100): #default 100 iterations\n",
    "    df = df\n",
    "    x = df.loc[:, df.columns != 'state'] #features\n",
    "    y = df.loc[:, df.columns == 'state'] #supervisor\n",
    "\n",
    "    eval_metrics = {} #empty dictionary to store metrics\n",
    "\n",
    "    for i in range(n_iter): \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.67)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        log_reg_model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "        pipeline = Pipeline(steps=[(\"scaler\", scaler), (\"log_reg\", log_reg_model)])\n",
    "\n",
    "        param_grid = {\n",
    "            'log_reg__C':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "        }\n",
    "\n",
    "        grid_model = GridSearchCV(pipeline, param_grid, n_jobs=1)\n",
    "        grid_model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "        y_pred = grid_model.predict(x_test)\n",
    "\n",
    "        accuracy = classification_report(y_test, y_pred, output_dict=True)['accuracy']\n",
    "        specificity = classification_report(y_test, y_pred, output_dict=True)['0']['recall'] #recall of the negative class = specificity\n",
    "        sensitivity = classification_report(y_test, y_pred, output_dict=True)['1']['recall'] #recall of the positive class = sensitivity\n",
    "\n",
    "        metrics = [accuracy, specificity, sensitivity] \n",
    "        eval_metrics[i]=list(metrics)\n",
    "\n",
    "    eval_metrics = pd.DataFrame.from_dict(eval_metrics).T \n",
    "    eval_metrics.columns = ['accuracy', 'specificity', 'sensitivity']\n",
    "    eval_metrics.head()\n",
    "\n",
    "    means = eval_metrics.mean(axis=0) #mean of each column\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet Packet / Wang, 8-7-02 data (wp8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy       0.955631\n",
       "specificity    0.954018\n",
       "sensitivity    0.956598\n",
       "dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_grid_reps(df = wp8, n_iter=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete Wavelet Transform, 8-7-02 data (dwt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy       0.951786\n",
       "specificity    0.951311\n",
       "sensitivity    0.952258\n",
       "dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_grid_reps(df = dwt8, n_iter=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
